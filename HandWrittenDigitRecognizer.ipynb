{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Test.csv', 'Train.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report \n",
    "import os\n",
    "print(os.listdir(\"input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/Train.csv')\n",
    "test = pd.read_csv('input/Test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.drop(columns='label',axis=1)/255\n",
    "y=train.label\n",
    "test = test/255\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "X_sparse = coo_matrix(X)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X, X_sparse, y = shuffle(X, X_sparse, y, random_state=0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.41902940\n",
      "Iteration 2, loss = 0.19573787\n",
      "Iteration 3, loss = 0.14533788\n",
      "Iteration 4, loss = 0.11952431\n",
      "Iteration 5, loss = 0.10368224\n",
      "Iteration 6, loss = 0.09241430\n",
      "Iteration 7, loss = 0.08287301\n",
      "Iteration 8, loss = 0.07631777\n",
      "Iteration 9, loss = 0.06944177\n",
      "Iteration 10, loss = 0.06546114\n",
      "Iteration 11, loss = 0.06199200\n",
      "Iteration 12, loss = 0.05835982\n",
      "Iteration 13, loss = 0.05535269\n",
      "Iteration 14, loss = 0.05423726\n",
      "Iteration 15, loss = 0.05197028\n",
      "Iteration 16, loss = 0.05031801\n",
      "Iteration 17, loss = 0.04924111\n",
      "Iteration 18, loss = 0.04828431\n",
      "Iteration 19, loss = 0.04741575\n",
      "Iteration 20, loss = 0.04641402\n",
      "Iteration 21, loss = 0.04592937\n",
      "Iteration 22, loss = 0.04513628\n",
      "Iteration 23, loss = 0.04489671\n",
      "Iteration 24, loss = 0.04426416\n",
      "Iteration 25, loss = 0.04380859\n",
      "Iteration 26, loss = 0.04364973\n",
      "Iteration 27, loss = 0.04301978\n",
      "Iteration 28, loss = 0.04275037\n",
      "Iteration 29, loss = 0.04251687\n",
      "Iteration 30, loss = 0.04206182\n",
      "Iteration 31, loss = 0.04188428\n",
      "Iteration 32, loss = 0.04154520\n",
      "Iteration 33, loss = 0.04130948\n",
      "Iteration 34, loss = 0.04110621\n",
      "Iteration 35, loss = 0.04070806\n",
      "Iteration 36, loss = 0.04041958\n",
      "Iteration 37, loss = 0.04048800\n",
      "Iteration 38, loss = 0.04023275\n",
      "Iteration 39, loss = 0.04005797\n",
      "Iteration 40, loss = 0.03987264\n",
      "Iteration 41, loss = 0.03971234\n",
      "Iteration 42, loss = 0.03960950\n",
      "Iteration 43, loss = 0.03940408\n",
      "Iteration 44, loss = 0.03927797\n",
      "Iteration 45, loss = 0.03913767\n",
      "Iteration 46, loss = 0.03894401\n",
      "Iteration 47, loss = 0.03891443\n",
      "Iteration 48, loss = 0.03883894\n",
      "Iteration 49, loss = 0.03854936\n",
      "Iteration 50, loss = 0.03845486\n",
      "Iteration 51, loss = 0.03853398\n",
      "Iteration 52, loss = 0.03830140\n",
      "Iteration 53, loss = 0.03815267\n",
      "Iteration 54, loss = 0.03805256\n",
      "Iteration 55, loss = 0.03796559\n",
      "Iteration 56, loss = 0.03788255\n",
      "Iteration 57, loss = 0.03791310\n",
      "Iteration 58, loss = 0.03773340\n",
      "Iteration 59, loss = 0.03772515\n",
      "Iteration 60, loss = 0.03766344\n",
      "Iteration 61, loss = 0.03750312\n",
      "Iteration 62, loss = 0.03726865\n",
      "Iteration 63, loss = 0.03742066\n",
      "Iteration 64, loss = 0.03742079\n",
      "Iteration 65, loss = 0.03740300\n",
      "Iteration 66, loss = 0.03718215\n",
      "Iteration 67, loss = 0.03734728\n",
      "Iteration 68, loss = 0.03717850\n",
      "Iteration 69, loss = 0.03702463\n",
      "Iteration 70, loss = 0.03707678\n",
      "Iteration 71, loss = 0.03707165\n",
      "Iteration 72, loss = 0.03687258\n",
      "Iteration 73, loss = 0.03680730\n",
      "Iteration 74, loss = 0.03668937\n",
      "Iteration 75, loss = 0.03668077\n",
      "Iteration 76, loss = 0.03650202\n",
      "Iteration 77, loss = 0.03651920\n",
      "Iteration 78, loss = 0.03644363\n",
      "Iteration 79, loss = 0.03663589\n",
      "Iteration 80, loss = 0.03668283\n",
      "Iteration 81, loss = 0.03639786\n",
      "Iteration 82, loss = 0.03631122\n",
      "Iteration 83, loss = 0.03634677\n",
      "Iteration 84, loss = 0.03628455\n",
      "Iteration 85, loss = 0.03627538\n",
      "Iteration 86, loss = 0.03626323\n",
      "Iteration 87, loss = 0.03611968\n",
      "Iteration 88, loss = 0.03623093\n",
      "Iteration 89, loss = 0.03622892\n",
      "Iteration 90, loss = 0.03602898\n",
      "Iteration 91, loss = 0.03615116\n",
      "Iteration 92, loss = 0.03619411\n",
      "Iteration 93, loss = 0.03610481\n",
      "Iteration 94, loss = 0.03593833\n",
      "Iteration 95, loss = 0.03609132\n",
      "Iteration 96, loss = 0.03587489\n",
      "Iteration 97, loss = 0.03589308\n",
      "Iteration 98, loss = 0.03598387\n",
      "Iteration 99, loss = 0.03593413\n",
      "Iteration 100, loss = 0.03586914\n",
      "Iteration 101, loss = 0.03588936\n",
      "Iteration 102, loss = 0.03585258\n",
      "Iteration 103, loss = 0.03587000\n",
      "Iteration 104, loss = 0.03587746\n",
      "Iteration 105, loss = 0.03573604\n",
      "Iteration 106, loss = 0.03591424\n",
      "Iteration 107, loss = 0.03574306\n",
      "Iteration 108, loss = 0.03563461\n",
      "Iteration 109, loss = 0.03567300\n",
      "Iteration 110, loss = 0.03563022\n",
      "Iteration 111, loss = 0.03576103\n",
      "Iteration 112, loss = 0.03562231\n",
      "Iteration 113, loss = 0.03555842\n",
      "Iteration 114, loss = 0.03557788\n",
      "Iteration 115, loss = 0.03555243\n",
      "Iteration 116, loss = 0.03555761\n",
      "Iteration 117, loss = 0.03552370\n",
      "Iteration 118, loss = 0.03571341\n",
      "Iteration 119, loss = 0.03543462\n",
      "Iteration 120, loss = 0.03535206\n",
      "Iteration 121, loss = 0.03549899\n",
      "Iteration 122, loss = 0.03545932\n",
      "Iteration 123, loss = 0.03551946\n",
      "Iteration 124, loss = 0.03547896\n",
      "Iteration 125, loss = 0.03533670\n",
      "Iteration 126, loss = 0.03541502\n",
      "Iteration 127, loss = 0.03531395\n",
      "Iteration 128, loss = 0.03543907\n",
      "Iteration 129, loss = 0.03527058\n",
      "Iteration 130, loss = 0.03532156\n",
      "Iteration 131, loss = 0.03521391\n",
      "Iteration 132, loss = 0.03531098\n",
      "Iteration 133, loss = 0.03530306\n",
      "Iteration 134, loss = 0.03515034\n",
      "Iteration 135, loss = 0.03546810\n",
      "Iteration 136, loss = 0.03533266\n",
      "Iteration 137, loss = 0.03519343\n",
      "Iteration 138, loss = 0.03529446\n",
      "Iteration 139, loss = 0.03527097\n",
      "Iteration 140, loss = 0.03517873\n",
      "Iteration 141, loss = 0.03507756\n",
      "Iteration 142, loss = 0.03522273\n",
      "Iteration 143, loss = 0.03519435\n",
      "Iteration 144, loss = 0.03514924\n",
      "Iteration 145, loss = 0.03505811\n",
      "Iteration 146, loss = 0.03517435\n",
      "Iteration 147, loss = 0.03511424\n",
      "Iteration 148, loss = 0.03496518\n",
      "Iteration 149, loss = 0.03507040\n",
      "Iteration 150, loss = 0.03502968\n",
      "Iteration 151, loss = 0.03493240\n",
      "Iteration 152, loss = 0.03508478\n",
      "Iteration 153, loss = 0.03508663\n",
      "Iteration 154, loss = 0.03493150\n",
      "Iteration 155, loss = 0.03512909\n",
      "Iteration 156, loss = 0.03493500\n",
      "Iteration 157, loss = 0.03499775\n",
      "Iteration 158, loss = 0.03494956\n",
      "Iteration 159, loss = 0.03488851\n",
      "Iteration 160, loss = 0.03487865\n",
      "Iteration 161, loss = 0.03494238\n",
      "Iteration 162, loss = 0.03487879\n",
      "Iteration 163, loss = 0.03495162\n",
      "Iteration 164, loss = 0.03493693\n",
      "Iteration 165, loss = 0.03485985\n",
      "Iteration 166, loss = 0.03498824\n",
      "Iteration 167, loss = 0.03482232\n",
      "Iteration 168, loss = 0.03480272\n",
      "Iteration 169, loss = 0.03475429\n",
      "Iteration 170, loss = 0.03475791\n",
      "Iteration 171, loss = 0.03481453\n",
      "Iteration 172, loss = 0.03476093\n",
      "Iteration 173, loss = 0.03487818\n",
      "Iteration 174, loss = 0.03492578\n",
      "Iteration 175, loss = 0.03472681\n",
      "Iteration 176, loss = 0.03480222\n",
      "Iteration 177, loss = 0.03481292\n",
      "Iteration 178, loss = 0.03471645\n",
      "Iteration 179, loss = 0.03483161\n",
      "Iteration 180, loss = 0.03476134\n",
      "Iteration 181, loss = 0.03479447\n",
      "Iteration 182, loss = 0.03471319\n",
      "Iteration 183, loss = 0.03463339\n",
      "Iteration 184, loss = 0.03468804\n",
      "Iteration 185, loss = 0.03462998\n",
      "Iteration 186, loss = 0.03462036\n",
      "Iteration 187, loss = 0.03465597\n",
      "Iteration 188, loss = 0.03463961\n",
      "Iteration 189, loss = 0.03454752\n",
      "Iteration 190, loss = 0.03473417\n",
      "Iteration 191, loss = 0.03465436\n",
      "Iteration 192, loss = 0.03466384\n",
      "Iteration 193, loss = 0.03469143\n",
      "Iteration 194, loss = 0.03461543\n",
      "Iteration 195, loss = 0.03458429\n",
      "Iteration 196, loss = 0.03459922\n",
      "Iteration 197, loss = 0.03462534\n",
      "Iteration 198, loss = 0.03466245\n",
      "Iteration 199, loss = 0.03455951\n",
      "Iteration 200, loss = 0.03456703\n",
      "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1202\n",
      "           1       0.99      0.98      0.99      1400\n",
      "           2       0.96      0.98      0.97      1246\n",
      "           3       0.97      0.97      0.97      1285\n",
      "           4       0.97      0.98      0.98      1223\n",
      "           5       0.98      0.97      0.98      1110\n",
      "           6       0.98      0.98      0.98      1283\n",
      "           7       0.97      0.97      0.97      1358\n",
      "           8       0.96      0.97      0.96      1198\n",
      "           9       0.97      0.95      0.96      1295\n",
      "\n",
      "    accuracy                           0.97     12600\n",
      "   macro avg       0.97      0.97      0.97     12600\n",
      "weighted avg       0.97      0.97      0.97     12600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100, ), \n",
    "                    max_iter=1000, alpha=0.03,\n",
    "                    solver='sgd', verbose=10, \n",
    "                    tol=0.00001, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9747619047619047"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      9\n",
       "4        5      3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subpred = clf.predict(test)\n",
    "submission = pd.read_csv('output/sample_res.csv')\n",
    "submission.Label = subpred\n",
    "submission.to_csv('output/sub.csv',index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
